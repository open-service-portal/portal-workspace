# Cloud-nativer Service-Marktplatz auf Kubernetes: Konzept und Architektur

## üìã Inhaltsverzeichnis

1. [Einf√ºhrung und Ziele](#einf√ºhrung-und-ziele)
2. [Architektur des Marktplatzes](#architektur-des-marktplatzes)
3. [Self-Service Interfaces](#self-service-interfaces)
4. [Sicherheit, Isolation und Governance](#sicherheit-isolation-und-governance)
5. [Risiken und Herausforderungen](#risiken-und-herausforderungen)
6. [Alternativen und Vergleich](#alternativen-und-vergleich)
7. [Fazit](#fazit)

## üéØ Einf√ºhrung und Ziele

Ein interner Cloud-Marktplatz soll es Entwicklern (interne Kunden) erm√∂glichen, komplexe Services selbst per Self-Service zu bestellen, ohne sich um die technischen Details der Infrastruktur k√ºmmern zu m√ºssen. Alles soll cloud-native umgesetzt werden ‚Äì im Kern auf Kubernetes basiert. Sogar externe Ressourcen wie DNS-Eintr√§ge oder Firewall-Regeln werden als Custom Resources (CRDs) in Kubernetes modelliert und verwaltet. Die Vision ist im Grunde eine Internal Developer Platform (IDP): Entwickler ordern per API, CLI oder Web-UI einen Service, und im Hintergrund werden alle ben√∂tigten Komponenten und Infrastruktur automatisch bereitgestellt Ôøº. Dies erh√∂ht die Autonomie der Entwickler und entlastet zentrale Teams, da keine manuellen Bereitstellungsprozesse mehr n√∂tig sind.

## üèóÔ∏è Architektur des Marktplatzes

### Technologie-Stack
- **Kubernetes** + **Crossplane** + **GitOps**

### Kubernetes als Control-Plane 
Der Marktplatz basiert auf einem Kubernetes-Cluster, der als zentrales Control-Plane f√ºr alle Services dient. Jeder Service wird durch einen Kubernetes Custom Resource (CR) repr√§sentiert. Dank Crossplane ‚Äì einem Open-Source-Projekt zur infrastrukturellen Erweiterung von Kubernetes ‚Äì k√∂nnen wir Cloud-Ressourcen und sogar nicht-Kubernetes-Komponenten als CRDs definieren und verwalten Ôøº. Crossplane installiert daf√ºr sogenannte Provider-Controller f√ºr verschiedene Cloud- und Infrastruktur-APIs und erm√∂glicht es, diese externen Ressourcen deklarativ √ºber Kubernetes zu steuern Ôøº Ôøº.

### Alles als CRD

F√ºr jeden angebotenen Service (egal ob ‚Äûkomplexer‚Äú Service wie eine Data-Science-Plattform oder ‚ÄûKomponenten‚Äú-Service wie eine PostgreSQL-Datenbank) wird ein eigener CRD-Typ definiert. Sogar Infrastruktur-Bausteine wie DNS-Eintr√§ge, Zertifikate oder Firewall-Regeln werden √ºber Crossplane-Provider in Kubernetes abgebildet, so dass s√§mtliche Bausteine im Marktplatz √ºber die Kubernetes-API verwaltet werden k√∂nnen. Dieses API-zentrierte Modell vermeidet Medienbr√ºche: Entwickler interagieren ausschlie√ülich mit Kubernetes-Objekten, nicht mit separaten Cloud-Konsolen oder Skripten Ôøº Ôøº. Zugangsdaten zu Cloud-Providern liegen nur bei Crossplane selbst (etwa als ProviderConfig mit hinterlegtem Secret), sodass Entwickler keine Cloud-Zugangsdaten ben√∂tigen und Berechtigungen zentral in Kubernetes verwaltet werden Ôøº Ôøº.

### Crossplane Compositions ‚Äì Abstraktion f√ºr Service-Owner

Ein zentrales Konzept ist die Abstraktion durch Crossplane-Compositions. Jeder Service-Typ erh√§lt eine benutzerfreundliche Oberfl√§chen-API (Custom Resource Definition), deren Spec nur die n√∂tigsten Eingabeparameter enth√§lt. Die Details der Umsetzung werden in einer Composition hinterlegt, die festlegt, welche konkreten Ressourcen im Hintergrund angelegt werden. Dadurch k√∂nnen komplizierte Setups in h√∂herwertige Ressourcen abstrahiert werden Ôøº Ôøº. Zum Beispiel kann es einen CRD-Typ PostgreSQLInstance geben, bei dem der Nutzer nur Parameter wie Datenbank-Gr√∂√üe und Version angibt ‚Äì Dinge wie VM-Instanzgr√∂√üe, Netzwerk oder Backup-Einstellungen sind in der Composition fest codiert durch den Service-Owner (Platform-Team) und f√ºr den Nutzer nicht sichtbar Ôøº. Crossplane k√ºmmert sich dann darum, beim Anlegen eines solchen CR alle erforderlichen Cloud-Ressourcen zu erzeugen (z.B. eine AWS RDS Instanz oder eine Azure PostgreSQL DB), ggf. inkl. erg√§nzender Ressourcen wie Subnetzen, DNS-Records oder IAM-Usern Ôøº Ôøº. F√ºr den Entwickler sieht das aus wie eine einzige Ressource in Kubernetes, die er erstellt ‚Äì die komplexen Details sind durch die Composition vor ihm verborgen Ôøº. Dieses Prinzip l√§sst sich auch verschachteln: Eine Composition kann mehrere unterliegende Ressourcen anlegen ‚Äì beispielsweise k√∂nnte die Bereitstellung einer AI-Data-Science-Plattform gleichzeitig eine PostgreSQL-Datenbank, einen S3-Speicher und einen Kafka-Cluster anlegen, indem die Composition intern die entsprechenden Component-Services als CRs erzeugt.

### Service Owner und Schichtung der Services

Daraus ergibt sich ein mehrstufiges Modell von Services mit jeweils eigenen Verantwortlichen (Service Owner):

#### 1Ô∏è‚É£ Infrastruktur-Services

Beispiele: ‚ÄûKubernetes-Cluster‚Äú, ‚ÄûDNS-Eintrag‚Äú, ‚ÄûTLS-Zertifikat‚Äú, ‚ÄûFirewall-Regel‚Äú. Diese werden meist vom zentralen Platform-Team bereitgestellt. Sie bilden die unterste Schicht und laufen oft als Crossplane-Managed Resources direkt auf Cloud-APIs (z.B. DNS via Route53, Cluster via EKS/AKS, etc.).

#### 2Ô∏è‚É£ Komponenten-Services

Wiederverwendbare technische Dienste wie PostgreSQL, MongoDB, Kafka, S3-Storage usw. Diese haben eigene Service Owner (Datenbank-Team, Messaging-Team, ‚Ä¶), die Experten f√ºr ihren Dienst sind. Sie nutzen die Infrastruktur-Services als Bausteine: Beispielsweise k√∂nnte der PostgreSQL-Service einen Kubernetes-Cluster oder eine VM ben√∂tigen, auf der die DB l√§uft, einen persistenten Storage und evtl. einen DNS-Eintrag f√ºr die DB-URL. All das bindet der DB-Service-Owner √ºber Crossplane ein, ohne die Details dieser Infrastruktur selbst manuell zu betreiben ‚Äì er deklariert nur in seiner Composition, dass z.B. ein DNSRecord-CR f√ºr die DB angelegt werden soll, und verl√§sst sich darauf, dass der DNS-Service-Owner daf√ºr gesorgt hat, dass DNSRecord-CRDs funktionieren. So kann jeder Komponenten-Service seine Abh√§ngigkeiten als weitere CRs modellieren, die wiederum von anderen Ownern geliefert werden.

#### 3Ô∏è‚É£ Komplexe Services

Das sind die Angebote, die der Endnutzer (Entwickler) letztlich bestellt, z.B. eine AI Data Science Plattform oder allgemein eine Entwicklungsumgebung, ein Jenkins-as-a-Service etc. Diese bestehen intern aus mehreren Komponenten-Services, werden aber als ein Produkt angeboten. Der Service-Owner eines komplexen Services definiert dessen CRD und Composition so, dass beim Anlegen z.B. einer AIPlatform-Resource automatisch alle ben√∂tigten Komponenten (Postgres, Kafka, ‚Ä¶ siehe oben) in Anspruch genommen werden. Wichtiges Akzeptanzkriterium ist hier: Der komplexe Service-Owner soll m√∂glichst nichts √ºber die Implementation der Komponenten-Services wissen m√ºssen. Er gibt in der Composition z.B. nur an ‚Äûf√ºr diese AIPlatform eine PostgreSQL-Instanz anlegen‚Äú (durch Erzeugen eines PostgreSQLInstance-CRs mit bestimmten Parametern). Wie genau der DB-Service diese Instanz bereitstellt, bleibt gekapselt in dessen Composition. Analog muss der Komponenten-Service-Owner (z.B. f√ºr PostgreSQL) die Infrastruktur darunter nicht im Detail kennen; er fordert z.B. √ºber einen Cluster-CR oder Speichervolumen-CR Infrastruktur an, ohne selbst direkt VMs zu konfigurieren ‚Äì diese Details stecken wiederum in den Infra-Service Compositions. Jeder k√ºmmert sich also nur um seine Abstraktion.

Durch diese Schichtung und Crossplane bleibt die Komplexit√§t in den unteren Schichten (Plattform-Team), w√§hrend die oberen Schichten einfache Interfaces haben Ôøº. Entwickler k√∂nnen so komplexe Anwendungen ordern, ohne von den zig Abh√§ngigkeiten dahinter zu wissen ‚Äì ‚ÄûEverything as a Service‚Äú innerhalb der Firma. Beim Bestellen der AI-Plattform etwa reicht ein CR anlegen; Crossplane erstellt daraus die DB, den Kafka, alle n√∂tigen Infrastrukturobjekte und nat√ºrlich den AI-Plattform-Dienst selbst, komplett automatisiert.

### Deployment der Services via GitOps

Die Service-Definitionen (CRDs, Compositions, etc.) leben in Git-Repositories ‚Äì pro Service gibt es z.B. ein eigenes GitHub-Repo mit seinen YAML-Definitionen. Ein GitOps-Werkzeug wie Flux oder Argo CD synchronisiert diese kontinuierlich ins Cluster. Das hei√üt, wenn ein Service-Owner sein Angebot weiterentwickelt (neue Version der Composition, neue CRD-Felder, etc.), reicht ein Commit und der GitOps-Operator wendet die √Ñnderungen im Kubernetes-Cluster an. So ist das Control-Plane-Cluster immer auf dem aktuellen Stand der gew√ºnschten Service-Katalog-Definitionen. Dies vereinfacht Updates und Versionierung enorm, da alle √Ñnderungen nachvollziehbar in Git historisiert sind.

**Beispiel**: Der Owner des PostgreSQL-Service pflegt in seinem Git-Repo die Crossplane-Composition, die einen AWS RDS-Postgres erstellt. Flux synchronisiert die CRD & Composition ins Cluster. Wenn er eine Optimierung vornimmt (z.B. anderen Instance-Typ oder Backup-Policy), committet er die √Ñnderung; Flux updatet die Composition. Neue Bestellungen nutzen dann automatisch die aktualisierte Definition.

```yaml
# Beispiel einer vereinfachten PostgreSQL Composition
apiVersion: apiextensions.crossplane.io/v1
kind: Composition
metadata:
  name: postgresql-aws
spec:
  compositeTypeRef:
    apiVersion: database.company.io/v1alpha1
    kind: PostgreSQLInstance
  resources:
    - name: rds-instance
      base:
        apiVersion: rds.aws.crossplane.io/v1alpha1
        kind: DBInstance
        spec:
          forProvider:
            region: eu-central-1
            engine: postgres
            engineVersion: "14"
            dbInstanceClass: db.t3.micro
            allocatedStorage: 20
```

Im Prototyp kann hierf√ºr jedes Managed-Kubernetes verwendet werden (z.B. ein Cluster in einer Umgebung wie Spot by NetApp oder Rackspace ‚Äì wichtig ist nur, dass Crossplane + GitOps darauf laufen k√∂nnen). F√ºr die Produktivumgebung w√ºrde man dann das Unternehmens-Cluster (oder Managed K8s in der Cloud) nutzen. Die Plattform ist prinzipiell Cloud-agnostisch, solange Crossplane-Provider f√ºr die genutzten Cloud-Dienste verf√ºgbar sind (AWS, Azure, GCP und viele weitere werden unterst√ºtzt).

## üñ•Ô∏è Self-Service Interfaces

### √úbersicht

Entwickler sollen die Services auf verschiedene Weisen bestellen k√∂nnen:

#### 1. Kubernetes CLI/API (kubectl)

Da alles √ºber Kubernetes-Objekte l√§uft, kann ein versierter Nutzer einfach per kubectl apply -f myservice.yaml den gew√ºnschten CR im Cluster erstellen. Das ist die direkteste Methode (bzw. via CI/CD Pipeline). Ebenso kann der Terraform Kubernetes Provider verwendet werden ‚Äì dieser erm√∂glicht es, Kubernetes-Ressourcen (also unsere Service-CRs) in Terraform-Manifeste einzubinden und so bereitzustellen. In beiden F√§llen spricht der Nutzer letztlich die Kubernetes-API an.

#### 2. Web-Frontend (Backstage)

F√ºr eine komfortable Bestelloberfl√§che setzen wir auf Backstage als Developer-Portal. Backstage pr√§sentiert den Katalog der verf√ºgbaren Services und erm√∂glicht es, √ºber Formular-Eingaben einen Service zu provisionieren. Hierzu integrieren wir Backstage eng mit unserem Kubernetes-GitOps-Flow:

##### Katalogintegration

Jede Service-Art (CRD) soll im Backstage-Katalog auftauchen, idealerweise ohne viel manuelle Pflege. Backstage bietet daf√ºr ein Kubernetes Ingestor-Plugin, das automatisch im Kubernetes-Cluster nach bestimmten Ressourcen sucht und sie als Components in den Catalog importiert Ôøº Ôøº. Insbesondere kann es Crossplane-Claims und -CRDs automatisch ingestieren: d.h. unsere angebotenen Service-CRDs erscheinen als Template oder Component in Backstage, ohne dass wir f√ºr jeden eine catalog-info.yaml von Hand schreiben m√ºssen Ôøº. Durch Annotationen an den CRDs/Resources l√§sst sich steuern, wie sie im Catalog dargestellt werden Ôøº Ôøº. Dies erspart viel manuelle Pflege, da der Katalog sich direkt aus der Kubernetes-Realit√§t speist.

##### Bestellvorgang √ºber GitOps

Im einfachsten Fall k√∂nnte Backstage direkt einen API-Call ans Cluster machen, um einen neuen CR zu erzeugen (√ºber ein Backend-Plugin mit ServiceAccount). Besser ist jedoch eine GitOps-Integration: Das TeraSky Crossplane-Plugin f√ºr Backstage erm√∂glicht, dass ein Bestellvorgang einen Pull Request in einem Git-Repo erzeugt, der den gew√ºnschten Custom Resource enth√§lt Ôøº. Dieser PR kann gepr√ºft und gemergt werden, woraufhin Flux/ArgoCD den neuen CR im Cluster anlegt. Dieses Vorgehen h√§lt alle √Ñnderungen unter Versionskontrolle und passt zu einem deklarativen Workflow (selbst Service-Bestellungen werden als Code erfasst). F√ºr den Prototyp kann man es aber auch zun√§chst pragmatisch halten (KISS-Prinzip) und Bestellungen direkt durchf√ºhren, w√§hrend man die GitOps-Anbindung sp√§ter verfeinert.

##### Visualisierung

Backstage dient nicht nur zur Bestellung, sondern auch zur √úbersicht und zum Status der laufenden Services. √úber das Crossplane-Resources-Plugin k√∂nnen wir auf der UI die Details eines bestellten Service-Instances einsehen ‚Äì inklusive der unterliegenden Ressourcen und sogar einer Graph-Visualisierung der Abh√§ngigkeiten Ôøº Ôøº. So kann ein Entwickler in Backstage z.B. sehen, dass seine AI-Plattform X eine PostgreSQL-DB Y und einen Bucket Z beinhaltet, und ob all diese gesund sind. Es gibt auch eine √úbersichtskarte pro Service-Component mit Status-Infos (Running, Fehler, etc.), was die Day-2 Operations erleichtert Ôøº Ôøº.

##### Authentifizierung und Berechtigungen

Backstage integriert sich mit Identity-Providern. Im Prototyp ist geplant, GitHub OAuth f√ºr Login zu nutzen (schnelle Einrichtung), w√§hrend produktiv nat√ºrlich die unternehmensweite Microsoft Entra ID (Azure AD) angebunden wird. Rollen und Berechtigungen k√∂nnen dann zentral gesteuert werden (z.B. welche Nutzer d√ºrfen welchen Service ordern). F√ºr den Prototyp steht jedoch Einfachheit im Vordergrund, komplexe RBAC-Policies werden zun√§chst ausgeklammert (man kann annehmen, dass alle internen Nutzer gleiche Rechte haben im Testsystem).

### üèóÔ∏è Zusammenfassung der Architektur-Komponenten

Die Architektur besteht aus folgenden Hauptkomponenten:

| Komponente | Funktion | Details |
|------------|----------|----------|
| **Kubernetes-Cluster** | Zentrale API-Plattform | Hostet alle CRDs und Control-Plane |
| **Crossplane** | Infrastructure-as-Code | Definiert CRDs f√ºr Services, managed Lebenszyklus |
| **GitOps** | Deployment & Sync | Flux/Argo CD synchronisiert Configs und Bestellungen |
| **Backstage** | Developer Portal | UI f√ºr Katalog, Bestellung, Status-Dashboards |
| **Identity Provider** | Auth & Access | GitHub (Prototyp) / Azure AD (Produktion) |

Ein solches Zusammenspiel von Backstage als UI, Crossplane als API-Layer und GitOps als Delivery-Mechanismus wird in der Platform-Engineering-Community als Best Practice angesehen Ôøº ‚Äì es liefert alle Bausteine, um eine interne Plattform bereitzustellen, die sowohl benutzerfreundlich (durch Backstage) als auch operationalisiert (durch K8s/Crossplane) ist.

## üîí Sicherheit, Isolation und Governance

Bei einem gemeinsamen Kubernetes-Cluster f√ºr den Marktplatz ist es wichtig, Multi-Tenancy und Zugriffsrechte sauber zu regeln. Crossplane und Kubernetes bieten hierf√ºr Mechanismen:

### Namespaces und RBAC

Wir planen, pro Team oder Anwendungsfall separate Namespaces zu nutzen. Entwickler erhalten nur Rechte in ‚Äûihrem‚Äú Namespace, um dort Service-Instanzen (Claims) anzulegen. Die CustomResourceDefinitions der Services k√∂nnen so gestaltet sein, dass sie namespaced Claims unterst√ºtzen ‚Äì d.h. der Entwickler legt z.B. ein DatabaseClaim in seinem Namespace an, w√§hrend Crossplane im Hintergrund eine clusterweite Ressource XDatabase verwaltet Ôøº Ôøº. √úber RBAC kann man Rechte vergeben wie ‚ÄûGruppe DataScientists darf im Namespace team-ds Objekte vom Typ AIPlatform (oder deren Claim) erstellen‚Äú. Aber sie d√ºrfen z.B. nicht direkt die low-level Infrastruktur-CRDs anlegen. So exponiert man nur die abstrahierten APIs auf Namespace-Ebene und sch√ºtzt die darunterliegenden Details Ôøº.

### Isolation der Provider Credentials

Crossplane erlaubt es, pro Namespace unterschiedliche Cloud-Credentials zu nutzen, indem die Composition das spec.providerConfigRef je nach Namespace patchen kann Ôøº. In unserem Kontext ist das ggf. relevant, falls verschiedene Projekte verschiedene Cloud-Accounts nutzen sollen. Im einfachsten Fall nutzen aber alle denselben Account, dann reicht eine globale Konfiguration (die ProviderConfig liegt im crossplane-system Namespace und wird von allen genutzt). Wichtig ist, dass Entwickler die Credentials nie direkt sehen ‚Äì nur Crossplane hat Zugriff, was ein Sicherheitsgewinn ist Ôøº.

### Policy Enforcement

In einer produktiven Plattform m√∂chte man Richtlinien durchsetzen, z.B. dass niemand eine DB gr√∂√üer als X GB ordert oder dass gewisse Tags gesetzt werden. Hierf√ºr lassen sich Admission Controller/Policy Engines wie Kyverno oder OPA Gatekeeper einsetzen. Crossplane selbst bietet in Compositions schon M√∂glichkeiten, Default-Werte zu setzen oder Eingaben zu validieren (via OpenAPI-Schema) Ôøº Ôøº. Dar√ºber hinaus k√∂nnten √ºbergreifende Policies mit Tools wie Kyverno kontrolliert werden ‚Äì das Backstage-Plugin unterst√ºtzt z.B. das Visualisieren von Kyverno Policy Reports direkt im UI Ôøº Ôøº. Im Prototyp werden wir Policies eher minimal halten (KISS), aber f√ºr den produktiven Betrieb ist dies ein wichtiger Aspekt (Governance).

### Trennung der Verantwortlichkeiten

Die oben beschriebene Service-Owner-Struktur bringt bereits eine gewisse Trennung mit sich. Jeder Service-Owner (z.B. Postgres-Team) entwickelt seine Composition und hat Schreibrechte darauf, aber ein anderer Service-Owner nicht. Man kann dies √ºber Git-Repos und CI/CD erzwingen (jeder Merge in die zentralen Configs geht √ºber Code Review durch das jeweilige Team). Innerhalb Kubernetes k√∂nnte man Crossplane in verschiedenen Scoping-Modi betreiben ‚Äì z.B. theoretisch mehrere Crossplane-Instanzen in unterschiedlichen Namespaces f√ºr verschiedene Teams (f√ºr unseren Use-Case vermutlich nicht n√∂tig, da Crossplane zentral okay ist). Entscheidend ist: Nur vertrauensw√ºrdige Admins d√ºrfen neue CRD-Typen (XRDs/Compositions) installieren; normale Dev-User d√ºrfen nur Instances/Claims erstellen. So bleibt die Kontrolle √ºber das ‚ÄûAngebotsportfolio‚Äú beim Plattform-Team.

### Authentifizierung und Auditing

Mit Azure AD als IdP wird sichergestellt, dass nur authentifizierte Mitarbeiter Zugriff haben. Jede Aktion (z.B. CR anlegen/l√∂schen) ist eine Kubernetes-API-Operation und somit im Audit-Log verfolgbar. Zudem pflegt GitOps ein Audit-Trail √ºber alle √Ñnderungen (Commits, PRs), was Revisionen nachvollziehbar macht.

### Abgrenzung Umgebungen

M√∂glicherweise trennt man Prototyp / Entwicklung von Produktion √ºber eigene Cluster oder zumindest Namespaces. Im Prototyp-Cluster kann mit Dummy-Services frei getestet werden. Sp√§ter k√∂nnte man Produktiv-Services auf einem dedizierten Crossplane-Cluster laufen lassen, der die echten Cloud-Ressourcen verwaltet, w√§hrend Entwickler ggf. in separaten Clustern arbeiten. Crossplane unterst√ºtzt sogar Multi-Cluster Szenarien (Control-Plane of Control-Planes), falls man beispielsweise die Service-CRDs zentral definieren, aber in mehreren Ziel-Clustern ausrollen will Ôøº Ôøº ‚Äì etwa um verschiedene Regionen oder Staging/Prod zu bedienen. Diese Komplexit√§t ist vorerst nicht n√∂tig, aber skalierbar.

### Secret-Management

Viele Services liefern Zugangsdaten (DB Credentials, API Keys). Crossplane legt solche Connection Secrets standardm√§√üig in einem Namespace (z.B. crossplane-system) ab Ôøº Ôøº. Man muss entscheiden, wie diese den Endnutzern zug√§nglich gemacht werden. Evtl. kopiert die Composition das Secret in den Namespace des Bestellers (Crossplane kann ConnectionDetails aus der Composition an √ºbergeordnete CRs propagieren Ôøº). Alternativ kann Backstage die Secrets auslesen und dem Nutzer anzeigen oder in ein Vault integrieren. Wichtig ist, hier keine Sicherheitsl√ºcken zu haben (Zugriff nur f√ºr berechtigte Nutzer auf ihre eigenen Secrets).

Zusammengefasst minimieren wir Risiken, indem wir strikte RBAC-Regeln, klar abgegrenzte Namespaces und pr√ºfbare Workflows (GitOps, CodeReviews) einsetzen. Damit bleibt das Selbstbedienungs-Portal kontrolliert und sicher, trotz hoher Autonomie f√ºr die Entwickler.

## ‚ö†Ô∏è Risiken und Herausforderungen

Trotz des vielversprechenden Konzepts gibt es einige Herausforderungen und Risiken zu beachten:
### üìà Steile Lernkurve & Kulturwandel
 Die Einf√ºhrung von Crossplane und dem Konzept ‚Äûalles als Kubernetes-Objekt‚Äú erfordert Schulung. Service-Owner m√ºssen lernen, Compositions zu schreiben (YAML, Verst√§ndnis der Provider-CRDs), Entwickler m√ºssen lernen, mit den abstrahierten CRDs umzugehen. Das ist zwar einfacher als direkt Terraform/Cloud-APIs zu bedienen, aber dennoch neu. Ohne Akzeptanz oder bei unzureichendem Training k√∂nnten Benutzer versucht sein, die Plattform zu umgehen.

### üèóÔ∏è Abstraktionsdesign & Wartbarkeit
 Die Qualit√§t der abstrahierten Services steht und f√§llt mit dem Design der CRD-Schnittstellen. W√§hlt ein Service-Owner die falschen Parameter (zu viele Details nach oben gereicht, oder zu unflexibel), leidet entweder die Benutzerfreundlichkeit oder die Nutzbarkeit. Es braucht also Guidelines f√ºr Service-Owner, was sie ihren Nutzern an Optionen geben und was sie intern fest hinterlegen. Auch m√ºssen Compositions versionierbar sein ‚Äì Crossplane erlaubt z.B. Composition Revisions, sodass bestehende Instanzen auf alter Version bleiben k√∂nnen, w√§hrend neue eine aktualisierte Composition nutzen.

### ‚ö†Ô∏è Fehler- und Konfliktbehandlung
 Bei automatisierter Kaskaden-Provisionierung ist das Fehlermanagement kritisch. Beispiel: Ein Data Scientist bestellt die AI-Plattform, dabei soll u.a. eine DB und ein Kafka entstehen. Was passiert, wenn die DB-Provisionierung fehlschl√§gt (z.B. Cloud-Quota erreicht)? Crossplane wird dies im Status der AIPlatform-Resource vermerken (Events, Conditions). Der Nutzer sieht dann ‚Äûprovisioning failed‚Äú. Es muss klar kommuniziert werden, wie in solchen F√§llen zu verfahren ist (Retry? Quota erh√∂hen? Support einschalten?). Die Plattform sollte m√∂glichst transparente Status-Infos liefern (Backstage-Plugin hilft hier, da es den Status jeder Teilressource zeigen kann).

### ‚è≥ Transiente Inkonsistenzen
 W√§hrend einer Bestellung werden Ressourcen sequenziell angelegt. Es kann Zeit dauern (eine DB kann mehrere Minuten brauchen). In dieser Zeit ist der Gesamtservice noch nicht einsatzbereit. Das ist normal, aber Nutzer sollten dies verstehen (z.B. Status ‚Äûim Aufbau‚Äú). Zudem muss Crossplane Abh√§ngigkeiten korrekt behandeln ‚Äì normalerweise definiert man implizite Abh√§ngigkeiten √ºber das Warten auf bereitgestellte Secrets oder Status der Sub-Ressourcen, was Crossplane erledigt. Dennoch gilt es, die Compositions sorgsam zu testen, damit alle patches & Verkn√ºpfungen stimmen Ôøº Ôøº (z.B. die DB-URL aus dem RDS-Secret ins AIPlatform-Secret propagieren etc.).

### üöÄ Performance und Skalierbarkeit
 Ein Kubernetes-Operator (Crossplane) hat Limits in Bezug auf wie viele Ressourcen er verwalten kann. Crossplane ist darauf ausgelegt, durchaus Hunderte bis Tausende von CRs zu managen, aber das Team sollte Monitoring einrichten (Prometheus Metrics von Crossplane) um sicherzustellen, dass die Reconciliation Loops performant laufen. In sehr gro√üen Umgebungen k√∂nnte eine Aufteilung auf mehrere Crossplane-Instanzen (pro Umgebung oder pro Team) erwogen werden Ôøº Ôøº. Im Prototyp spielt das keine Rolle, aber bei Erfolg muss man die Skalierbarkeit im Auge behalten.

### üéØ Crossplane Maturity & Provider-Abdeckung
 Crossplane selbst ist CNCF Incubation Project (Stand 2025) und wird rege weiterentwickelt. Viele Unternehmen nutzen es produktiv, aber es bleibt ein komplexes System. Man muss die Updates im Auge behalten. Die Provider (z.B. f√ºr AWS, Azure) sollten genau auf ihre Version und Stabilit√§t gepr√ºft werden ‚Äì nicht jeder Provider ist gleich weit gereift. F√ºr manche Spezialdienste gibt es evtl. (noch) keinen fertigen Provider. In solchen F√§llen m√ºsste man Workarounds nutzen (z.B. Crossplane-Provider f√ºr Terraform Provider Jet, um eine Terraform-Konfiguration auszuf√ºhren, falls Crossplane direkt etwas nicht kann). Diese L√ºcken gilt es fr√ºh zu identifizieren, damit keine b√∂sen √úberraschungen auftreten, wenn ein bestimmter Service doch nicht vollst√§ndig automatisierbar ist.

### üîí Lock-in und Alternativen
 Indirekt begibt man sich auf einen Pfad, der von bestimmten Tools abh√§ngt (Crossplane, ArgoCD, Backstage). Allerdings sind dies Open-Source-L√∂sungen, die on-premise betrieben werden, also kein klassischer Vendor-Lock-in. Dennoch: Sollte Crossplane sich in Zukunft nicht durchsetzen oder das Unternehmen eine andere Strategie fahren, steht man vor einer Migration der Plattform. Gl√ºcklicherweise abstrahiert Crossplane nur auf Kubernetes-Standard ‚Äì d.h. im Worst Case hat man ‚Äûnur‚Äú Kubernetes-Manifeste, die man evtl. anders interpretieren muss. Der Marktplatz-Ansatz an sich ist aber unabh√§ngig vom konkreten Tool implementierbar.

### üí∞ Ressourcenkosten und Governance
 Self-Service kann zu unkontrolliertem Ressourcenverbrauch f√ºhren, wenn keine Leitplanken existieren. Pl√∂tzlich hat jeder Entwickler dutzende DB-Instances laufen. Hier m√ºssen wir vorsorgen: z.B. Quotas pro Namespace, Freigabeprozesse f√ºr besonders teure Services, oder wenigstens Transparenz √ºber laufende Kosten. Crossplane selbst hat keine eingebaute Kostenkontrolle, aber man k√∂nnte etwa ein Billing-Export an Backstage anbinden oder Alerts definieren. Dieses Thema ist organisatorisch zu kl√§ren (wer tr√§gt Kosten, Freigaben etc.), geh√∂rt aber zu den Risiken.

### ‚ôæÔ∏è Lifecycle und Cleanup
 Wenn ein Nutzer einen Service nicht mehr braucht und den CR l√∂scht, sorgt Crossplane daf√ºr, dass alle untergeordneten Ressourcen aufger√§umt werden (inkl. Cloud-Ressourcen). Das ist super f√ºr automatisches Cleanup ‚Äì aber birgt auch Risiko: Daten k√∂nnten verloren gehen, wenn versehentlich etwas gel√∂scht wird. Evtl. m√∂chte man Schutzmechanismen (‚Äûdo not delete prod DB without approval‚Äú). Crossplane bietet z.B. sog. DeletionPolicy an manchen Ressourcen (z.B. Retain statt Delete). In Compositions kann man das ber√ºcksichtigen. F√ºr den Prototyp reicht der Default (l√∂schen l√∂scht alles), doch produktiv muss man festlegen, welche Services kritische persistent data haben und ggf. eine Grace-Period oder Backup vor L√∂schen einplanen.

### üîÑ CI/CD f√ºr Service-Implementierungen
 Neben der Crossplane-Ebene gibt es ja auch die eigentlichen Service-Komponenten. Z.B. k√∂nnte der AI-Plattform-Service aus einer Sammlung von Microservices bestehen, die als Docker-Images vorliegen. Diese m√ºssen gebaut (GitHub Actions) und irgendwo deployt werden (vielleicht als Helm Chart via Crossplane‚Äôs Helm-Provider, oder √ºber ArgoCD als Teil der Composition). Wir haben Dummy-Services, aber sobald es real wird, brauchen wir Deployment-Pipelines f√ºr die eigentlichen Service-Anwendungen. Dies geh√∂rt zur technischen Umsetzung ‚Äì im Konzept nehmen wir an, dass Service Owner ihre Komponenten containerisieren und versionieren. Der Marktplatz orchestriert dann deren Deployment (z.B. in einem gemeinsamen Cluster oder dedizierten Cluster pro Instanz). Das ist ein weiteres Workstream (Images bauen, registries, etc.), das parallel angegangen werden muss, um die Plattform end-to-end lauff√§hig zu machen.

### üé® Backstage-Integrationsaufwand
 Die erw√§hnten Backstage-Plugins (Kubernetes Ingestor, Crossplane UI, etc.) stammen aus Open-Source (z.B. von TeraSky) und m√ºssen ins eigene Backstage integriert werden. Das ist zwar machbar, aber erfordert etwas Frontend-/Backend-Arbeit im Backstage-Projekt (Plugins installieren, Konfigurieren gem. Doku Ôøº Ôøº). Man sollte daf√ºr Zeit einplanen. Auch muss Backstage selbst gehostet und gewartet werden (Updates, Plugins pflegen). Als Alternative g√§be es gehostete Backstage (z.B. SaaS von Roadie) ‚Äì dort sind die Plugins teils schon integriert Ôøº Ôøº. Aber beim Prototyp vermutlich Self-Hosted Backstage im Cluster.

### üîç Beobachtbarkeit und Debugging
 Es wurde schon angesprochen, aber nochmal: Wenn etwas schiefgeht, m√ºssen Platform-Teams in der Lage sein, schnell die Ursache zu finden. Crossplane schreibt Events, Logs ‚Äì man sollte zentral logging/monitoring haben (ELK/ Loki, Prometheus). Auch f√ºr Performance-Metriken (Crossplane Reconcile Zeiten, etc.) gibt es Telemetrie. Dies stellt sicher, dass das Platform-Team Probleme beheben kann, bevor Nutzer frustriert aufgeben.

Trotz dieser Herausforderungen √ºberwiegen die Vorteile: Entwicklerzufriedenheit durch Self-Service, konsistente Automatisierung, und klare Verantwortlichkeiten je Service. Viele der Risiken lassen sich durch Policies, Schulung und schrittweises Herantasten (erst Dummy-Services, dann kritische Services) mitigieren.

## üîÑ Alternativen und Vergleich

Das vorgeschlagene Konzept setzt stark auf Kubernetes und Crossplane. Es gibt jedoch alternative Ans√§tze, die in Betracht gezogen werden k√∂nnen oder bei der Bewertung helfen:

### Kubernetes Service Catalog / Open Service Broker (OSB)
 Dies war fr√ºher der Kubernetes-Weg, externe Services bereitzustellen. √úber einen ServiceBroker und die OSB-API konnten Entwickler ServiceInstances anlegen, die dann z.B. eine DB in der Cloud provisionierten. In OpenShift existiert(e) so ein Service Catalog. Allerdings ist dieses Modell inzwischen etwas veraltet und die Kubernetes-Community hat das Projekt eingestellt. Zudem waren die vom Broker bereitgestellten CRDs relativ generisch und nicht gut in moderne GitOps-Workflows integriert. Unser Crossplane-Ansatz erreicht √§hnliches (Self-Service DB etc.), aber auf Kubernetes-native Weise und mit mehr Flexibilit√§t bei den Schnittstellen (wir k√∂nnen unsere eigenen CRDs definieren statt nur vorgegebene Plans des Brokers). OSB eignet sich weniger, wenn man sehr individuelle interne Services hat ‚Äì es war eher f√ºr Standard-Cloud-Services gedacht.

### Direkte Terraform/Pulumi-Portal-L√∂sungen
 Einige Unternehmen bauen interne Portale, die bei Klick im Hintergrund Terraform-Skripte ausf√ºhren, um Infrastruktur aufzusetzen. So etwas k√∂nnte man mit z.B. ServiceNow oder einer WebUI + Terraform Cloud umsetzen. Das erf√ºllt den Zweck eines Marktplatzes auch (Katalog, Bestellung, Automation). Nachteile: Man hat zwei Welten ‚Äì Kubernetes f√ºr Apps, Terraform f√ºr Infra ‚Äì und keine gemeinsame Kontrolle. Entwickler m√ºssten eventuell trotzdem die Besonderheiten der Terraform-Module kennen, was wieder die H√ºrde erh√∂ht. Zudem fehlt die kontinuierliche Reconciliation: Terraform f√ºhrt einmal aus, w√§hrend Crossplane als Operator st√§ndig drift behebt und in Kubernetes integriert ist. Unser Kubernetes-zentrischer Ansatz sorgt f√ºr eine einheitliche Plattform-API und Echtzeit-Self-Service, was mit stand-alone Terraform schwieriger zu erreichen ist (aber es ist durchaus eine Alternative, falls man Kubernetes meiden wollte).

### KubeVela (OAM)
 KubeVela ist ein Framework basierend auf dem Open Application Model, das ebenfalls abstrakte API-Schichten √ºber Kubernetes legt. Es richtet sich prim√§r auf Anwendungen/Workloads, kann aber auch Infrastruktur einbinden (z.B. via Crossplane). KubeVela erlaubt Platform-Teams, sogenannte Components und Traits vordefiniert anzubieten, aus denen Entwickler ihre Deployments bauen. Mit Vela k√∂nnte man z.B. einen Component-Typ ‚ÄûPostgresDB‚Äú definieren, der intern Crossplane nutzt. Es bietet auch eine UI (VelaUX). Der Unterschied: KubeVela ist eher fokussiert auf Applikationsrollouts und Developer Experience, w√§hrend Crossplane auf Infrastruktur fokussiert ist. In unserem Fall, wo es um expliziten Marktplatz mit Multi-Service-Abh√§ngigkeiten geht, ist Crossplane direkter passend. Allerdings kann KubeVela als erg√§nzende Ebene dienen, um App-Deployment (CI/CD) mit Infrastruktur provisioning zu vereinen. F√ºr den Prototyp ist es wahrscheinlich Overkill, aber es ist gut zu wissen, dass OAM/KubeVela existiert als Alternative, falls Crossplane allein nicht alle W√ºnsche erf√ºllt.

### KRO ‚Äì Kubernetes Resource Orchestrator (von AWS)
 Ganz neu (Ende 2024) hat AWS ein Open-Source-Projekt namens KRO vorgestellt Ôøº. Es verfolgt ein √§hnliches Ziel wie Crossplane ‚Äì n√§mlich eigene Plattform-APIs zu definieren, die multiple Ressourcen orchestrieren ‚Äì aber mit einem anderen Ansatz. Anstatt zwei Ebenen (XRD + Composition) zu schreiben, deklariert man bei KRO alles in einem Konstrukt namens ResourceGroup, das alle Komponenten beschreibt Ôøº Ôøº. KRO generiert daraus automatisch die ben√∂tigten CRDs und Controller zur Laufzeit. Im Prinzip spart es etwas Komplexit√§t bei der Definition. Allerdings ist KRO derzeit experimentell (Beta) und noch nicht produktionsreif Ôøº. Crossplane ist deutlich ausgereifter. Langfristig k√∂nnte KRO interessant werden, da es Abh√§ngigkeiten und Reihenfolgen automatisch managen will Ôøº. F√ºr unsere Entscheidung hei√üt das: Wir beobachten KRO, bleiben aber vorerst bei Crossplane, weil Stabilit√§t und Community-Support wichtiger sind als Cutting-Edge-Experimente.

### Kratix (Syntasso)
 Kratix ist ein weiteres Open-Source-Framework, das genau die Idee ‚ÄûMarktplatz f√ºr XaaS‚Äú adressiert. Es f√ºhrt den Begriff Promise ein ‚Äì ein Versprechen eines Service, das von Platform Engineers erstellt wird. Wenn ein Entwickler ein Promise anfordert, sorgt Kratix daf√ºr, dass der n√∂tige Service bereitgestellt wird. Intern kann Kratix z.B. Crossplane nutzen, um die Umsetzung zu erledigen. Der Vorteil von Kratix: Es bietet out-of-the-box eine Marketplace-Mechanik und unterst√ºtzt Multi-Cluster, d.h. man kann eine zentrale Kontrolle haben, die Services dann in Ziel-Clustern provisioniert. Syntasso (die Firma dahinter) vermarktet eine Enterprise-Version, aber die OSS-Version erf√ºllt viele Kernfunktionen. Kratix versteht sich als ‚Äûintelligenter Kleber‚Äú zwischen Frontend und IaC-Backends Ôøº. Es erlaubt Plattform-Teams, alles als Service anzubieten, konsumierbar √ºber UI, API oder CLI, w√§hrend z.B. Crossplane im Hintergrund die Infrastruktur baut Ôøº. Im Grunde √§hnelt das unserem Ansatz, aber Kratix liefert schon gewisse Strukturen und ein Community-Marketplace (f√ºr g√§ngige Promises) mit. Als Alternative k√∂nnte man also in Betracht ziehen: statt selbst alles mit Crossplane + Backstage zu kombinieren, ein Framework wie Kratix zu nutzen, das diese Kombination vereinfacht. Allerdings w√ºrde man sich dann in dessen Konzept einarbeiten m√ºssen, und die Flexibilit√§t ist an das Framework gebunden. In unserer Konstellation haben wir bereits Backstage vorgesehen (was gut mit Kratix integrierbar w√§re) und schreiben unsere Crossplane Compositions selbst ‚Äì was maximal flexibel ist. Kratix lohnt sich vielleicht zu evaluieren, falls wir feststellen, dass viel wiederkehrende Muster auftreten, die es schon als Kratix-Promise gibt.

### Eigenentwicklung / Operators
 Schlie√ülich gibt es immer die Option, ma√ügeschneiderte Operatoren f√ºr jeden Service zu schreiben (z.B. einen ‚ÄûAIPlatform-Operator‚Äú in Go, einen ‚ÄûPostgres-Operator‚Äú etc.). Das w√§re der traditionelle Weg vor Crossplane: Jedes Team implementiert einen Kubernetes-Operator, der seinen Service managt. Dies bietet volle Kontrolle, ist aber aufw√§ndig, da viel Code geschrieben und gewartet werden muss (Controller-Logik, CRD-Schemas etc.). Crossplane reduziert diesen Aufwand drastisch, indem es als Meta-Operator fungiert ‚Äì neue APIs und deren Implementierung werden durch Konfiguration statt Code erzeugt Ôøº. Damit erspart man sich eine Flut eigenentwickelter Controller. Angesichts der Ressourcen im Team und der gew√ºnschten Geschwindigkeit scheidet ein komplett eigener Operator-Ansatz aus ‚Äì stattdessen nutzen wir Crossplane als Framework, was sich bereits als effizient erwiesen hat.

### Fazit zu Alternativen
 F√ºr unseren Anwendungsfall (interner Cloud-Marktplatz, starke Kubernetes-Ausrichtung) ist Crossplane mit GitOps und Backstage eine sehr passende L√∂sung, da sie Cloud-native Prinzipien (Deklarativit√§t, Self-Service, API-Standardisierung) vereint. Die genannten Alternativen zeigen, dass das Konzept im Trend liegt ‚Äì andere Projekte wie KubeVela, Kratix, KRO zielen in eine √§hnliche Richtung, mit teils anderen Schwerpunkten. Dies best√§tigt unsere Grundidee. Gleichzeitig sollten wir die Entwicklung am Markt beobachten: z.B. k√∂nnte eine Kombination aus Crossplane und KRO k√ºnftig Best Practices sein, oder Kratix k√∂nnte manche Funktionen (Multi-Cluster, Paketierung) bequemer l√∂sen. F√ºr den Moment bauen wir jedoch auf bew√§hrte Komponenten auf, die gut zusammenspielen.

## üéØ Fazit

Das skizzierte Konzept zeichnet einen Weg zu einem Kubernetes-basierten Service-Marktplatz, der Entwicklern eine moderne Self-Service-Plattform bietet. Durch den Einsatz von Crossplane als Erweiterung der Kubernetes-API k√∂nnen wir komplexe Infrastruktur hinter einfachen Custom Resources verbergen, sodass jede Fachdom√§ne (Datenbanken, Messaging, Plattform etc.) ihren Service selbst als API-Produkt anbieten kann Ôøº. Mit GitOps wird Konsistenz und Nachvollziehbarkeit garantiert, w√§hrend Backstage als einheitliches Portal die Benutzererfahrung abrundet.

Wichtig ist, neben der Technik auch Prozesse und Kultur anzupassen ‚Äì etwa klare Verantwortlichkeiten (Service Owner), Schulung der Nutzer und Richtlinien f√ºr sichere Nutzung. Starten werden wir mit einem Prototypen (z.B. auf einem Managed-K8s-Cluster in einer Sandbox-Umgebung) und Dummy-Services wie MongoDB, PostgreSQL, Kafka, DNS, Firewall, um diese Ideen in kleiner Skalierung zu validieren. In diesem Schritt k√∂nnen wir die Integration (CI-Pipelines, GitHub Actions, Container-Deployments nach Spot/Rackspace etc.) aufbauen und evaluieren, bevor es an kritische produktive Services geht.

Alles in allem verspricht dieser cloud-native Marktplatzansatz erhebliche Vorteile: schnellere Bereitstellung f√ºr Entwickler, weniger manuelle Tickets, konsistente Infrastruktur nach Best Practices und eine hohe Wiederverwendbarkeit von Komponenten. Die m√∂glichen Risiken ‚Äì von Komplexit√§t bis Governance ‚Äì sind beherrschbar, wenn wir sie von Anfang an ber√ºcksichtigen und mit Bedacht vorgehen. Das Konzept ist modular erweiterbar und offen f√ºr neue Tools, sodass wir auch in Zukunft modern und flexibel bleiben k√∂nnen. Damit schaffen wir die Grundlage f√ºr eine interne Cloud-Plattform, die unseren Entwicklern Innovation in Eigenregie erm√∂glicht, ohne dass dabei Chaos oder Unsicherheit entstehen. Der Weg ist anspruchsvoll, aber die Ergebnisse werden die Developer Experience und Effizienz ma√ügeblich verbessern.